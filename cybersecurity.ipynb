{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "386255dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfiltered UNSW_NB15_test-set.csv dataframe shape: (82332, 45)\n",
      "Unfiltered UNSW_NB15_training-set.csv dataframe shape: (175341, 45)\n",
      "\n",
      " Columns in both files are the same! \n",
      "\n",
      "Filtered UNSW_NB15_test-set.csv dataframe shape: (82332, 45)\n",
      "Filtered UNSW_NB15_training-set.csv dataframe shape: (175341, 45)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "'''\n",
    "Checking for same column names\n",
    "'''\n",
    "\n",
    "test_file = 'UNSW_NB15_test-set.csv'\n",
    "train_file = 'UNSW_NB15_training-set.csv'\n",
    "\n",
    "test_df = pd.read_csv(os.path.join('data', test_file))\n",
    "train_df = pd.read_csv(os.path.join('data', train_file))\n",
    "print('Unfiltered ' + test_file + ' dataframe shape: ' + str(test_df.shape))\n",
    "print('Unfiltered ' + train_file + ' dataframe shape: ' + str(train_df.shape))\n",
    "\n",
    "# Find common columns between test and training datasets\n",
    "test_columns = set(test_df.columns)\n",
    "train_columns = set(train_df.columns)\n",
    "if test_columns == train_columns:\n",
    "    print('\\n Columns in both files are the same! \\n')\n",
    "\n",
    "common_columns = test_columns.intersection(train_columns)\n",
    "filtered_test_df = test_df[list(common_columns)]\n",
    "filtered_train_df = train_df[list(common_columns)]\n",
    "\n",
    "# Write the filtered dataframes back to CSV files\n",
    "filtered_test_df.to_csv(test_file, index=False)\n",
    "filtered_train_df.to_csv(train_file, index=False)\n",
    "\n",
    "test_df = pd.read_csv(os.path.join('data', test_file))\n",
    "train_df = pd.read_csv(os.path.join('data', train_file))\n",
    "print('Filtered ' + test_file + ' dataframe shape: ' + str(test_df.shape))\n",
    "print('Filtered ' + train_file + ' dataframe shape: ' + str(train_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2943e9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values only in training data:\n",
      "None found!\n",
      "Values only in testing data:\n",
      "None found!\n",
      "proto:\n",
      "{'gre', 'netblt', 'sps', 'sep', 'pim', 'ggp', 'sprite-rpc', 'leaf-2', 'bbn-rcc', 'fc', 'l2tp', 'ospf', 'a/n', 'sun-nd', 'mobile', 'pri-enc', 'ipv6-no', 'sdrp', 'rvd', 'igmp', 'xtp', 'ipnip', 'bna', 'emcon', 'larp', 'pipe', 'mhrp', 'rsvp', 'compaq-peer', 'argus', 'dcn', 'uti', 'encap', 'gmtp', 'irtp', 'aris', 'secure-vmtp', 'isis', 'merit-inp', 'iso-ip', 'cftp', 'tcp', 'br-sat-mon', 'ipv6-route', 'wb-expak', 'stp', 'ipv6', 'iplt', 'skip', 'rdp', 'cphb', 'st2', 'ipv6-opts', 'unas', 'ipcv', 'ipv6-frag', 'trunk-2', 'mtp', 'hmp', 'iatp', 'ddx', 'ipx-n-ip', 'idpr', 'udp', 'vines', 'leaf-1', 'idrp', 'i-nlsp', 'crudp', 'cbt', 'chaos', 'igp', 'aes-sp3-d', 'pup', 'sctp', 'arp', 'mux', 'scps', 'pnni', 'micp', 'eigrp', 'kryptolan', 'pvp', 'any', 'ptp', 'fire', 'sccopmce', 'narp', 'wsn', 'srp', 'dgp', 'nsfnet-igp', 'smp', 'sat-mon', 'egp', '3pc', 'ip', 'prm', 'vrrp', 'tlsp', 'nvp', 'ifmp', 'sat-expak', 'wb-mon', 'iso-tp4', 'snp', 'trunk-1', 'ttp', 'vmtp', 'tp++', 'ddp', 'cpnx', 'zero', 'mfe-nsp', 'ippc', 'etherip', 'visa', 'ax.25', 'crtp', 'ib', 'pgm', 'tcf', 'swipe', 'idpr-cmtp', 'xns-idp', 'il', 'ipip', 'qnx', 'ipcomp', 'sm', 'xnet'}\n",
      "\n",
      "Values only in training data:\n",
      "None found!\n",
      "Values only in testing data:\n",
      "None found!\n",
      "service:\n",
      "{'-', 'http', 'ftp', 'pop3', 'irc', 'ftp-data', 'dns', 'ssh', 'ssl', 'dhcp', 'snmp', 'smtp', 'radius'}\n",
      "\n",
      "Values only in training data:\n",
      "Values only in testing data:\n",
      "state:\n",
      "{'INT', 'REQ', 'FIN', 'CON', 'RST'}\n",
      "\n",
      "Values only in training data:\n",
      "None found!\n",
      "Values only in testing data:\n",
      "None found!\n",
      "attack_cat:\n",
      "{'Analysis', 'Normal', 'Worms', 'DoS', 'Shellcode', 'Exploits', 'Generic', 'Backdoor', 'Reconnaissance', 'Fuzzers'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Remove all the records with categorical values that only appear in training and test data.\n",
    "'''\n",
    "\n",
    "proto_values = None\n",
    "service_values = None\n",
    "state_values = None\n",
    "attack_cat = None\n",
    "categorical_columns = {'proto': proto_values, \n",
    "                       'service': service_values, \n",
    "                       'state': state_values, \n",
    "                       'attack_cat': attack_cat}\n",
    "\n",
    "for key in categorical_columns.keys():\n",
    "    test_values = set(test_df[key])\n",
    "    train_values = set(train_df[key])\n",
    "    print('Values only in training data:')\n",
    "    deleted_values = test_values - train_values\n",
    "    if not deleted_values:\n",
    "        print('None found!')\n",
    "    print('Values only in testing data:')\n",
    "    if not deleted_values:\n",
    "        print('None found!')\n",
    "    deleted_values = train_values - test_values\n",
    "    common_values = test_values.intersection(train_values)\n",
    "    categorical_columns[key] = common_values\n",
    "    print(key + ':')\n",
    "    print(common_values)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2b7619",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Encode categorical features and normalize numeric features.\n",
    "'''\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyber_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
